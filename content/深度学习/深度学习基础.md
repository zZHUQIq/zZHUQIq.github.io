# 名词解释
1. 随机变量：随机事件的数量表现，随机事件数量化的好处是可以用数学分析的方法来研究随机现象。![[Pasted image 20240509203527.png]]
2. **线性可分与线性不可分**：![[Pasted image 20240510145203.png]]
3. 机器学习：![[Pasted image 20240509212518.png]]![[Pasted image 20240509213050.png]]
4. **激活函数**：![[Pasted image 20240509220313.png]]![[Pasted image 20240510193128.png]]
# 数学基础
1. 最小二乘法求多元线性回归的目标函数最优解：![[Pasted image 20240509200028.png]]***注***：arg min使后面这个式子达到最小值时的变量的取值。![[Pasted image 20240509200129.png]]
2. 向量：![[Pasted image 20240509200951.png]]***注***：向量的转置就是向量的行变成列(行和列互换)的意思
3. 张量：![[Pasted image 20240509201230.png]]
4. 矩阵：![[Pasted image 20240509201324.png]]![[Pasted image 20240509201432.png]]![[Pasted image 20240509201736.png]]
	1. 矩阵的秩：![[Pasted image 20240509201954.png]]
	2. 矩阵的逆：![[Pasted image 20240509202608.png]]![[Pasted image 20240509202741.png]]
	3. 矩阵的分解：![[Pasted image 20240509202827.png]]
		1. 特征分解：![[Pasted image 20240509202920.png]]
		2. 奇异值分解：![[Pasted image 20240509203052.png]]
5. **最小二乘法**：【回归问题】它通过最小化误差的平方和寻找 数据的最佳函数匹配。![[Pasted image 20240509203228.png]]
6. 概率分布：![[Pasted image 20240509205209.png]]![[Pasted image 20240509205226.png]]![[Pasted image 20240509205241.png]]![[Pasted image 20240509205335.png]]
	1. 概率定义：![[Pasted image 20240509205441.png]]![[Pasted image 20240509205525.png]]
	2. 概率公式：![[Pasted image 20240509205952.png]]
7. 常用统计量：
	1. **期望**：在概率和统计学中，数学期望是试验中每次可能结果的概率乘以其结果的总和，反映随机变量平均值的大小![[Pasted image 20240509210140.png]]
	2. **方差**：随机变量与数学期望之间的偏离程度![[Pasted image 20240509210247.png]]
	3. **协方差**：衡量两个随机变量X和Y之间的总体误差![[Pasted image 20240509210510.png]]
8. **损失函数**：将随机事件或其有关随机变 量的取值映射为非负实数以表示该随机事件的“风险” 或“损失”的函数![[Pasted image 20240509210856.png]]![[Pasted image 20240509210914.png]]![[Pasted image 20240509211155.png]]![[Pasted image 20240509210835.png]]
	1. 回归问题中的损失函数：![[Pasted image 20240509211237.png]]
	2. 分类问题损失函数：![[Pasted image 20240509211349.png]]![[Pasted image 20240509211430.png]]![[Pasted image 20240509211606.png]]
9. 信息论
	1. 熵增定律：孤立系统总是趋向于熵增，最终达到熵的最大状态，也就是系统的最混乱无序状态。但是，对开放系统而言，由于它可以将内部能量交换产生的熵增通过向环境释放热量的方式转移，所以开放系统有可能趋向熵减而达到有序状态。
	2. 信息熵：样本集合纯度一种指标，也可以认为是样本集合包含的平均信息量![[Pasted image 20240509212013.png]]
	3. 联合熵：两个随机变量X和Y的联合分布可以形成联合熵，用来度量二维随机变量 X,Y的不确定性![[Pasted image 20240509212053.png]]
	4. 条件熵：![[Pasted image 20240509212148.png]]![[Pasted image 20240509212208.png]]
	5. **相对熵**：KL散度![[Pasted image 20240509212244.png]]
# 机器学习基础
1. 数据集：![[Pasted image 20240509212638.png]]
2. 数据集分类：![[Pasted image 20240509212752.png]]![[Pasted image 20240509212919.png]]
3. 误差：![[Pasted image 20240509212957.png]]
4. **过拟合与欠拟合**：![[Pasted image 20240509213032.png]]
5. 机器学习分类
	1. 无监督：![[Pasted image 20240509213134.png]]
		1. **聚类**：对一批没有类别标签的样本集，按照样本之间的相似程度分类， 相似的归为一类，不相似的归为其它类。这种分类称为**聚类分析**，也称为无监督分类。目的是“将数据分成多个类别，在同一个类内，对象 （实体）之间具有较高的相似性，在不同类内，对象之间具有较大的差异性”。![[Pasted image 20240509215122.png]]
		2. **降维**：目的是“将原始样本数据的维度𝑑降低到一个更小的数𝑚，且尽量使得样本蕴含信息量损失最小，或还原数据时产生的误差最小”。![[Pasted image 20240509215236.png]]![[Pasted image 20240509215304.png]]
	2. 有监督：![[Pasted image 20240509213211.png]]
		1. **线性回归**：最小二乘法求损失函数![[Pasted image 20240509213326.png]]
		2. **逻辑回归**：sigmoid函数![[Pasted image 20240509213540.png]]
		3. **支持向量机**：![[Pasted image 20240509213721.png]]![[Pasted image 20240509213932.png]]![[Pasted image 20240509214017.png]]
		4. 决策树：是一种基于树结构进行决策的机器学习方法，这恰是人类面临决策时一种很自然的处理机制。![[Pasted image 20240509214236.png]]***注***：信息增益就代表熵增![[Pasted image 20240509214717.png]]
		5. 随机森林：该算法用随机的方式建立起一棵棵决策树，然后由这些决策树组成一个森林，其中每棵决策树之间没有关联。![[Pasted image 20240509214816.png]]![[Pasted image 20240509214912.png]]

# 神经元模型——M-P模型：![[Pasted image 20240509220054.png]]![[Pasted image 20240509220346.png]]![[Pasted image 20240510143036.png]]
# 感知器以及多层感知器
1. **感知器定义**：与 M-P模型需要人为确定参数不同，感知器能够通过训练自动确定参数。训练方式为有监督学习，即需要设定训练样本和期望输出，然后调整实际输出和期望输出之差的方式（误差修正学习）。![[Pasted image 20240510143427.png]]![[Pasted image 20240510143842.png]]![[Pasted image 20240510144144.png]]
2. 训练过程：![[Pasted image 20240510144432.png]]
3. 感知器与线性问题：
	1. **单层感知器**：只有一个神经元![[Pasted image 20240510144626.png]]![[Pasted image 20240510144721.png]]
	2. **多层感知器**：![[Pasted image 20240510144901.png]]![[Pasted image 20240510145249.png]]

# BP算法
1. 定义：![[Pasted image 20240510145617.png]]![[Pasted image 20240510145928.png]]
2. BP**算法的瓶颈以及解决方案**：![[Pasted image 20240510150050.png]]![[Pasted image 20240510150341.png]]***注***：这里阐释了激活函数的重要性以及为什么不用MP模型的阶跃函数做激活函数。
3. BP算法的**例子**：![[Pasted image 20240510150835.png]]![[Pasted image 20240510150724.png]]![[Pasted image 20240510150950.png]]![[Pasted image 20240510151100.png]]
