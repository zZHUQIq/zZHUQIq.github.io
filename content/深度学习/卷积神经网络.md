1. 起源：神经认知机【大脑中的信息处理不仅仅是简单的信号传递，而是通过神经元之间的复杂交互和网络连接来实现的。这种交互作用涉及到大脑各个部分之间的动态调节和协调，包括感知、注意、记忆、决策等各种认知功能。】![[Pasted image 20240509194943.png]]
2. 发展：![[Pasted image 20240509195009.png]]
3. 为什么需要卷积运算？——大图像会存在参数灾难的问题，导致计算量过大![[Pasted image 20240510155717.png]]![[Pasted image 20240510155919.png]]
4. 什么是梯度消失？![[Pasted image 20240510192220.png]]

# 计算题——卷积的运算
1. 运算公式：![[Pasted image 20240510153550.png]]![[Pasted image 20240510154814.png]]![[Pasted image 20240510154837.png]]
2. 例子：
	1. 求两个骰子之和为4的概率![[Pasted image 20240510153640.png]]![[Pasted image 20240510153805.png]]***注***：一维离散卷积
	2. 求复利——在时间上连续![[Pasted image 20240510154430.png]]![[Pasted image 20240510154706.png]]
2. **二维图像的卷积运算**：相当于卷积核覆盖灰色位置，然后进行每个数值对应起来乘积然后求和得到输出的特征图。![[Pasted image 20240510160244.png]]![[Pasted image 20240510160514.png]]
	* 不同的filter:![[Pasted image 20240510160854.png]]
	* **边缘扩充**：原图像经过卷积运算后，新图像会变的更小，并且中间的像素会在卷积运算后特征得到较大的保留，而边缘的像素参与到卷积运算的机会少，特征很难体现。![[Pasted image 20240510161532.png]]![[Pasted image 20240510161843.png]]***注***：Same卷积要求输出图像与输入图像的长宽都保持一致，且注意f一般为奇数，因为此时卷积核保有中心对称点，在特征提取的时候保留图形的对称状态。【这个公式的步长为1，若步长大于1，公式改变】![[Pasted image 20240510162246.png]]***注***：计算时注意向下取整，即对不含特征的卷积核不进行计算

# 卷积神经网络的架构分类
**典型的卷积神经网络基本架构**——由卷积层（含激活函数）、池化层、全连接层和输出层构成，其中卷积层与池化层一般交替排列，之后接一层或者多层全连接层，最后是输出层。
	1. 卷积层：![[Pasted image 20240510163742.png]]![[Pasted image 20240510162607.png]]![[Pasted image 20240510162624.png]]![[Pasted image 20240510162804.png]]
		1. 单通道卷积：一般提取图像的边缘![[Pasted image 20240510162909.png]]
		2. 多通道卷积：![[Pasted image 20240510162935.png]]![[Pasted image 20240510163829.png]]***注***：过滤器对不同层可以进行不同的特征提取，也可以添加过滤器得到一个多通道的特征图，如下![[Pasted image 20240510164032.png]]![[Pasted image 20240510163317.png]]***注***：只有一个过滤器，得到的特征图就是单通道的
	2. 激活函数：激活函数的引入，增强了人工神经网络的非线性表达能力，从而提高了模型的学习能力。• 在卷积神经网络中，为了缓解梯度消失问题，常用的激活函数有ReLU、PReLU、ERU和Maxout等【见ppt】![[Pasted image 20240510192701.png]]***注***：MAXOUT激活函数如下![[Pasted image 20240511105212.png]]
	3. 池化层：池化操作使用某位置相邻输出的总体统计特征作为该位置的输出，常用最大池化（max-pooling）和均值池化（average pooling）
	4. 输出层：![[Pasted image 20240511110940.png]]
1. 卷积运算大致流程：
	1. **卷积核**：特征过滤器【提取特征】——但是这样会导致边缘特征【比如你只能再垂直和水平中提取一个方向的信息】丢失，因此需要padding把原始图扩充 ，提取两个方向的边缘特征。
	2. **最大池化**：仅反映最突出的特征——如：6x6的图用2x2的网格分割成3x3的部分，然后提取每个部分的最大值，进而保留原始图中最精华的部分![[Pasted image 20240324170551.png]]
	3. **扁平化处理**【全连接层：可以将不同的区域特征合并为一个完整的特征】：池化后的数据，把两个3x3的像素图进行叠加，转化成一维的数据条，数据条录入到后面的全连接层——产生输出结果![[Pasted image 20240324170802.png]]![[Pasted image 20240324171513.png]]
2. 卷积神经网络的训练：见PPT54 
3. 典型卷积神经网络：
	1. LeNet-5：手写数字识别和英文字母识别
		* 基本结构：带可学习参数有多少层就说明卷积神经网络有多少层![[Pasted image 20240320084940.png]]![[Pasted image 20240320085312.png]]***注***：C1层没有填充，所以大小变小![[Pasted image 20240320085423.png]]![[Pasted image 20240320085618.png]]***注***：卷积核个数n代表对n个通道进行信息提取，即卷积![[Pasted image 20240320085854.png]]![[Pasted image 20240320085953.png]]![[Pasted image 20240320090130.png]]![[Pasted image 20240320090251.png]]![[Pasted image 20240320090309.png]]
		* 卷积核大小、卷积核个数（特征图需要多少个）、池化核大小和步长等这些参数都是变化的，这就是所谓的CNN调参，需要学会根据需要进行不同的选择。
	2. AlexNet：![[Pasted image 20240511114435.png]]
	3. VGGNet：每一个卷积层组后面接**最大池化**降低分辨率
	4. GoogleNet：解决梯度消失
	5. ResNet：残差单元![[Pasted image 20240320094952.png]]

# 卷积神经网络的应用
1. R-CNN应用：目标检测【框出目标，识别类别】![[Pasted image 20240511114952.png]]
	1. SPPNET：(SIM模式)卷积层不改变输入图像的分辨率【维度】，池化层会降低分辨率【在卷积层和全连接层输出固定维度】![[Pasted image 20240325084649.png]]![[Pasted image 20240325085117.png]]![[Pasted image 20240325085426.png]]***注***：**分别均匀划分成不同的分辨率**，最后组合成固定长度的向量作为全连接层的输入。
	2. Fast R-CNN![[Pasted image 20240325085632.png]]![[Pasted image 20240325090046.png]]![[Pasted image 20240325090358.png]]***注***：提取候选框+提取特征——!先提proposal，然后CNN提取特征，之后用SVM分类器，最后再做Bbox回归进行候选框的微调；在CNN提取特征后，做一个RoI pooling，再将候选框目标分类与Bbox回归同时放入全连接层，形成一个multi-task模型。![[Pasted image 20240325090451.png]]![[Pasted image 20240325092919.png]]
	3. Faster R-CNN：由于RPN的存在，精度更好![[Pasted image 20240325093148.png]]***注***：RPN形成候选框，分类【是否包含目标】、回归【矫正】![[Pasted image 20240325094142.png]]
4. Yolo：单阶段检测框架![[Pasted image 20240325094510.png]]![[Pasted image 20240325095405.png]]
5. **图像分割**：FCN网络——对图片中每一个像素分类![[Pasted image 20240511145034.png]]![[Pasted image 20240511145810.png]]***注***：除此之外，SegNet和UNet
6. **姿态估计**：神经网络前——比较依赖先验信息![[Pasted image 20240327094050.png]]![[Pasted image 20240511150523.png]]
	1. DeepPose：第一个关键点位置对图像进行裁剪作为输入，输入后得到的预测点与第一个关键点进行差值评估——框回归【预测候选框和真实框的偏差】——精度越来越高![[Pasted image 20240327094935.png]]![[Pasted image 20240327095243.png]]![[Pasted image 20240327095522.png]]
	2. Stacked Hourglass：关键点转化成包含K个关键点的预测热图【类似于图像分割】![[Pasted image 20240327100831.png]]![[Pasted image 20240327100817.png]]
7.  人脸识别
	1. LFW：判断两张照片是否来自同一个人【**人脸验证**】![[Pasted image 20240511153228.png]]
	2. DeepFace(CNN)：检测，对齐（校正），表示，分类![[Pasted image 20240401085749.png]]***注***：后3个卷积核不共享【提取的特征区域不同：精细特征】，但这会导致卷积层的参数量显著增加
	3. DeepID：输入是局部区域【先裁剪，后提特征】，深层和浅层的最大池化层作为输出——保留细节![[Pasted image 20240401090537.png]]***注***：将不同区域提取到的DeepID 连接起来作为人脸的特征，用PCA降维到150维后送入Joint Bayesian分类器（也可以是其他分类器）进行人脸验证，此时变为二分类任务
	4. FaceNet：![[Pasted image 20240401091441.png]]![[Pasted image 20240511153531.png]]