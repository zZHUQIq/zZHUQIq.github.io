1. **定义**：以房屋为例，除了面积外，还有其他因素，如房屋卧室数目，层数等来共同影响房屋的价格，这些因素共同组成一个可以输入的**行向量**![[Pasted image 20240423205632.png]]![[Pasted image 20240423210012.png]]***注***：b可以看作是基线，即房屋起价![[Pasted image 20240423210403.png]]***注***：Multiple linear regression——多元线性回归可以用两个行向量的点乘来简化【矢量化】

# 矢量化
1. np.dot——把code简化，提高运行速度![[Pasted image 20240423212346.png]]***注***：python的**代码计数从0**开始，因此range(0,n)实际代表的是0—n-1![[Pasted image 20240423212416.png]]![[Pasted image 20240423212931.png]]
2. 例：矢量化实现并行计算![[Pasted image 20240423213257.png]]
# 梯度下降用于多元线性回归
1. 定义：矢量化的过程![[Pasted image 20240425111521.png]]
2. 梯度下降：更新W1—Wn![[Pasted image 20240425112453.png]]
3. 梯度下降实现：
	1. 功能缩放：
		1. 对于较大的x，模型对w的预测需要尽可能小![[Pasted image 20240425114434.png]]![[Pasted image 20240425114648.png]]![[Pasted image 20240425114832.png]]
		2. 如何进行缩放：![[Pasted image 20240506143023.png]]***注***：这是通过分别除最大值来实现的缩放![[Pasted image 20240506143337.png]]***注***：均值归一化![[Pasted image 20240506143635.png]]***注***：Z-score均一化
		3. 总结：![[Pasted image 20240506143917.png]]
	2. 检查梯度下降**是否收敛**：
		1. 关于学习曲线：如果J在迭代的过程中上升意味着学习率α太大，或者是代码错误！![[Pasted image 20240506144647.png]]
		2. 自动收敛测试：如果J的减少幅度小于ε，课证明收敛![[Pasted image 20240506144937.png]]
	3. 选择**学习率**：
		1. 学习率过高的危害：![[Pasted image 20240506145410.png]]
		2. 尝试一系列不同的α值![[Pasted image 20240506145608.png]]