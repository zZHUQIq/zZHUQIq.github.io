——基础工具
1. 第一章【基本概念】：![[Pasted image 20240518162253.png]]
2. 第二章【贝尔曼公式】：**策略评价**![[Pasted image 20240518162313.png]]
3. 第三章【贝尔曼最优公式】：强化学习的最终目标？【求解最优策略】![[Pasted image 20240518163002.png]]
——算法和反馈
4. 第四章【最优策略的算法】：有模型的值迭代/策略迭代![[Pasted image 20240518163307.png]]
5. 第五章【无模型的】：不需要模型找最优策略——学习随机变量的期望值【通过随机采样、MC basic/MC Exploring Starts/MC ɛ-greedy 】![[Pasted image 20240518165825.png]]
6. 第六章【随机近似理论】：from non-incremental【如我有一万个样本，我要等采样所有后才求平均】 to incremental【开始有一个可能不准的估计，得到一次采样就更新一次估计】![[Pasted image 20240518170513.png]]
7. 第七章【时序差分】：![[Pasted image 20240518170540.png]]
8. 第八章【状态连续或状态特别多时的——函数Vhat】：神经网络首次进入到强化学习中![[Pasted image 20240518171003.png]]
9. 第九章【由value-based到policy-based的跳跃】：![[Pasted image 20240518171259.png]]
10. 第十章【policy-based+value-based】：![[Pasted image 20240518171447.png]]
11. 课程是否适合你？——**课程特点**：强化学习的原理；数学的角度讲故事

# 强化学习背景
1. AlphaGo：
	1. 围棋界战无不胜——掀起强化学习的热潮
	2. AlphaGo Zero：战胜AlphaGo
2. 强化学习历史：
	1. Deep Q-learning：Q-learning【特殊的Temporal-difference learing时序差分】
	2. Dynamic programming【动态规划】：离散时间/离散状态
3. 强化学习分类
	1. 人工智能
	2. 机器学习
4. 强化学习的范式：![[Pasted image 20240520192859.png]]