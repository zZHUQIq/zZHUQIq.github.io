# 策略目标函数
1. 定义：给出策略Πθ(s,a)，求出最好的参数θ【建模的过程】
2. 片段式环境+连续性环境——策略最优化
3. 策略梯度：沿梯度方向使J(𝜃)上升至局部最大值
4. 模型策略：
	1. Softmax：梯度是当前动作偏好的梯度与所有动作偏好梯度均值的差
	2. 高斯分布策略+线性函数策略(连续动作空间)
	3. 单步马尔科夫决策过程【短期回报的梯度】——多步【策略不变，长期平均总回报代替一步回报】
	4. 有终止条件的策略优化目标：采样或TD差分求期望——优化整个轨迹的奖励
	5. 无终止条件：所有回报的衰减求和的期望——平均回报
5. 策略梯度的计算：
	1. 似然比代表该条轨迹到策略目标函数最优值的梯度
	2. 时间连续性：动作没有发生之前的奖励不产生影响
6. 策略评估【策略选择+价值评估的过程】：用**critic**对行为价值进行估计并用于指导策略更新
	* Actor-critic ：价值学习率通常比策略学习率大，这样才能进行知道策略的迭代，Qw是中间值，因此会存在一定偏差——兼容性【w是价值的参数，θ是策略的参数】
	* 兼容近似函数：近似价值函数对于策略兼容【终点和过程无偏——收敛】
	* 适应基线减少方差：利用达到稳态的状态价值做基线【理想状态，利用初始的V0做B】——对方差有影响
	* 优势函数——TD误差【每一步的TD误差作为当时的优势函数来用】